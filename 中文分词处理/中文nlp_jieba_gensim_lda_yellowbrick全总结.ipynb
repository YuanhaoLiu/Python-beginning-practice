{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （以自己为例，中文全流程总结）\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 预处理之分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.load_userdict('your_userdict_txt')\n",
    "stopwords = open('your_stopwords_txt', 'r', encoding = 'utf8').readlines()\n",
    "stopwords = [w.strip() for w in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行分词\n",
    "\n",
    "tr = []\n",
    "\n",
    "fr = open('your_txt_to_process','r',encoding='utf-8')\n",
    "for w in fr.readlines():\n",
    "    w = w.strip()      # 移除字符串首尾指定的字符\n",
    "    w = \"\".join(w.split())\n",
    "    if not len(w):                    # 看是否是空行\n",
    "        continue\n",
    "        \n",
    "    outstr = ''                          # 给一个字符串\n",
    "    \n",
    "    w = re.sub(r'[A-Za-z0-9]|/d+','',str(w)) # 正则一下\n",
    "    \n",
    "    seg_list = jieba.lcut(w, cut_all=False)   # 精确结巴\n",
    "    for word in seg_list:\n",
    "        if word not in stopwords:            # 看是否在stopwords中\n",
    "            if word != '\\t':                 # ！= 不是制表符\n",
    "                outstr += word\n",
    "                outstr += \" \"\n",
    "            \n",
    "    tr.append(outstr.strip().split(\" \"))    # 往这个list里取出空白且分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把结果写入\n",
    "\n",
    "with open('your_out_txt','w',encoding = 'utf-8') as file:\n",
    "    file.write(str(tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结巴自带算法看下关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jieba import analyse\n",
    "tfidf = analyse.extract_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('your_out_txt','r',encoding='utf-8') as file:\n",
    "    texts = file.readlines()\n",
    "keywords = jieba.analyse.extract_tags(str(texts), topK=50, withWeight=True, allowPOS=('nr','ns','nt','nz','n','vn','v'))\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 导入gensim 建 LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models import ldaseqmodel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import Dictionary, bleicorpus\n",
    "import pyLDAvis.gensim\n",
    "import numpy\n",
    "from gensim.matutils import hellinger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['font.sans-serif'] = ['Simhei']\n",
    "plt.rcParams.update({'font.size': 22})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('your_out_txt','r',encoding='utf-8') as file:\n",
    "    texts = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 那个结果的txt拆出来变成list of words \n",
    "\n",
    "import ast\n",
    "\n",
    "tr = [inner for item in texts for inner in ast.literal_eval(item)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 选择合适的topic k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(tr)\n",
    "corpus = [dictionary.doc2bow(text) for text in tr]\n",
    "time_slice = [] # 如果要做dtm，后面就省略在这里写了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=tr, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score using UMass\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=tr, dictionary=dictionary, coherence=\"u_mass\")\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model=LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=corpus, texts=tr, start=2, limit=40, step=6)\n",
    "\n",
    "# Show graph\n",
    "\n",
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 可视化LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis_data = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save html\n",
    "pyLDAvis.save_html(vis_data, 'your_output.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dtm 动态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaseq = ldaseqmodel.LdaSeqModel(corpus=corpus, id2word=dictionary, time_slice=time_slice, num_topics=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 打印出每个时期的k个主题并拼接（因为我不会写循环哈哈哈哈，所以超级笨的办法）\n",
    "\n",
    "frame1 = pd.DataFrame(ldaseq.print_topics(time=0))\n",
    "frame2 = pd.DataFrame(ldaseq.print_topics(time=1))\n",
    "frame3 = pd.DataFrame(ldaseq.print_topics(time=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [frame1,frame2, frame3]\n",
    "project_dtm_result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存结果在csv里\n",
    "\n",
    "project_dtm_result. to_csv('paperDtmResult1.csv', encoding = 'utf_8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Yellowbrick可视化\n",
    "\n",
    "#### Token frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from yellowbrick.text import FreqDistVisualizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "docs = vectorizer.fit_transform(texts)\n",
    "features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = FreqDistVisualizer(features=features, n=30, orient='v', size = (700,480), color = 'k')\n",
    "visualizer.fit(docs)\n",
    "plt.xticks(rotation=60)\n",
    "plt.tick_params(labelsize = 16)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dispersion plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.text import DispersionPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example\n",
    "\n",
    "target_words = ['城市','路灯','大数据','农业', '物流']\n",
    "visualizer = DispersionPlot(target_words)\n",
    "visualizer.fit(tr)\n",
    "visualizer.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
