{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping with python \n",
    "\n",
    "Edited on Sep 23\n",
    "\n",
    "This book attempted to cover the use of databases, web servers, HTTP, HTML, internet security, image processing, data science, and other tools.\n",
    "\n",
    "## Part I building scrapers\n",
    "\n",
    "+ Retrieving HTML data from a domain name\n",
    "+ Parsing that data for target information\n",
    "+ Storing the target information\n",
    "+ Optionally, moving to another page to repeat the process\n",
    "\n",
    "## Chapter 1 Your first web scraper\n",
    "\n",
    "开头是一个computer之间交流的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')   ## 注意是逗号，我疯了 检查了五分钟才发现  或者也可以直接 BeautifulSoup(html.'html.parser')\n",
    "print(bs.h1)   # This returns only the first instace of the h1 tag found on the page.\n",
    "               # <h1> defines the most important heading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An introduction to BeautifulSoup\n",
    "\n",
    "html.read() get the content of the page\n",
    "\n",
    "HTML content could be transfomred into a BS object, with the structure (html--body--h1)\n",
    "\n",
    "Another popular parser is lxml. It is generally better at parsing \"messy\" or malformed HTML code than html.parser. \n",
    "\n",
    "Another popular HTML parser is html5lib.\n",
    "\n",
    "### Connecting Reliably and Handling Exceptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "try:\n",
    "    html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "    # return null, break, or other plan B\n",
    "except URLError as e:\n",
    "    print('The server could not be found!')\n",
    "else:\n",
    "    ptint('It Worked!')\n",
    "    # program continues (写了return或break的就不用else了)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced HTML Parsing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna\n",
      "Pavlovna Scherer\n",
      "Empress Marya\n",
      "Fedorovna\n",
      "Prince Vasili Kuragin\n",
      "Anna Pavlovna\n",
      "St. Petersburg\n",
      "the prince\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "the prince\n",
      "the prince\n",
      "the prince\n",
      "Prince Vasili\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "the prince\n",
      "Wintzingerode\n",
      "King of Prussia\n",
      "le Vicomte de Mortemart\n",
      "Montmorencys\n",
      "Rohans\n",
      "Abbe Morio\n",
      "the Emperor\n",
      "the prince\n",
      "Prince Vasili\n",
      "Dowager Empress Marya Fedorovna\n",
      "the baron\n",
      "Anna Pavlovna\n",
      "the Empress\n",
      "the Empress\n",
      "Anna Pavlovna's\n",
      "Her Majesty\n",
      "Baron\n",
      "Funke\n",
      "The prince\n",
      "Anna\n",
      "Pavlovna\n",
      "the Empress\n",
      "The prince\n",
      "Anatole\n",
      "the prince\n",
      "The prince\n",
      "Anna\n",
      "Pavlovna\n",
      "Anna Pavlovna\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://www.pythonscraping.com/pages/warandpeace.html')\n",
    "bs = BeautifulSoup(html.read(),'html.parser')\n",
    "\n",
    "nameList = bs.findAll('span', {'class':'green'})   # bs.find_all(tagName, tagAttributes)\n",
    "for name in nameList:\n",
    "    print(name.get_text())                         # .get_text() strips all the tags and returns a unicode string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find() and find_all() in BS\n",
    "\n",
    "find_all(tag, attributes, recursive, text, limit, keywords)  \n",
    "\n",
    "find(tag, attributes, recursive, text, keywords)\n",
    "\n",
    "常用的是tag 和 attributes  \n",
    "\n",
    "The keyword argument allows you to select tags that contain a particular attribute of set of attributes.  \n",
    "\n",
    "title = bs.find_all(id='title', class_='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "nameList = bs.find_all(text='the prince')\n",
    "print(len(nameList))                              # find the number of times \"the prince\" surrounded by tags on the example page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other BS Objects\n",
    "\n",
    "BeautifulSoup objects  \n",
    "\n",
    "Tag objects  \n",
    "\n",
    "NavigableString Objects -- used to represent text with tags, rather than the tags themselves  \n",
    "\n",
    "Comment Object -- used to find HTML comments in comment tags, <!--like this one-->\n",
    "\n",
    "\n",
    "### Navigating trees\n",
    "\n",
    "To find a tag based on its location in a document\n",
    "\n",
    "**Dealing with children and other descendants **  两者区别就相当于亲生孩子和直属后代\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<tr><th>\n",
      "Item Title\n",
      "</th><th>\n",
      "Description\n",
      "</th><th>\n",
      "Cost\n",
      "</th><th>\n",
      "Image\n",
      "</th></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift1\"><td>\n",
      "Vegetable Basket\n",
      "</td><td>\n",
      "This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
      "<span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\n",
      "</td><td>\n",
      "$15.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img1.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift2\"><td>\n",
      "Russian Nesting Dolls\n",
      "</td><td>\n",
      "Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n",
      "</td><td>\n",
      "$10,000.52\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img2.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift3\"><td>\n",
      "Fish Painting\n",
      "</td><td>\n",
      "If something seems fishy about this painting, it's because it's a fish! <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>\n",
      "</td><td>\n",
      "$10,005.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img3.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift4\"><td>\n",
      "Dead Parrot\n",
      "</td><td>\n",
      "This is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n",
      "</td><td>\n",
      "$0.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img4.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift5\"><td>\n",
      "Mystery Box\n",
      "</td><td>\n",
      "If you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. <span class=\"excitingNote\">Keep your friends guessing!</span>\n",
      "</td><td>\n",
      "$1.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img6.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://www.pythonscraping.com/pages/page3.html')\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "for child in bs.find('table',{'id':'giftList'}).children:     ## find only descendants that are children\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dealing with siblings**  \n",
    "\n",
    "next_siblings()    它只会返回object itself之后的sibling  \n",
    "\n",
    "**Dealing with parents**  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions   \n",
    "\n",
    "star -- match 0 or more times  \n",
    "加号  -- match 1 or more times  \n",
    "[]      match any character with the brackets(pick one of these things)  \n",
    "()      a grouped subexpression  \n",
    "{m,n}  match the preceding character, subexpression, or bracketed character between m and n times(inclusive)  \n",
    "[^]    match any single character that is not in the brackets  \n",
    "|      match any (or)  \n",
    ".      match any gingle character(including symbols, numbers, a space, etc.)  \n",
    "^      indicate a character or subexpression occurs at the beginning of a string ^a  \n",
    "\\      An escape character 转义  \n",
    "$      Often used at the end of a regular expression  \n",
    "?!     Doe not contain  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../img/gifts/img1.jpg\n",
      "../img/gifts/img2.jpg\n",
      "../img/gifts/img3.jpg\n",
      "../img/gifts/img4.jpg\n",
      "../img/gifts/img6.jpg\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "html = urlopen('http://www.pythonscraping.com/pages/page3.html')\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "images = bs.find_all('img',\n",
    "                    {'src':re.compile('\\.\\.\\/img\\/gifts/img.*\\.jpg')})\n",
    "for image in images:\n",
    "    print(image['src'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Attributes\n",
    "\n",
    "With tag objects, a Python list of attributes can be automatically accessed by calling this:  \n",
    "\n",
    "myTag.attrs  -- this literally returns a Pytho dictionary object  \n",
    "\n",
    "## Lambda Expressions 闭包\n",
    "\n",
    "就是原来要f(x,y) lambda可以弄为f(g(x),h(x))  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 Writing Web Crawlers\n",
    "\n",
    "## Traversing a Single Domain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/wiki/Kyra_Sedgwick\n",
      "/wiki/Sosie_Bacon\n",
      "/wiki/Sleepers\n",
      "/wiki/Screen_Actors_Guild_Award\n",
      "/wiki/Social_networks\n",
      "/wiki/Six_Degrees_of_Kevin_Bacon\n",
      "/wiki/SixDegrees.org\n",
      "/wiki/Julia_R._Masterman_High_School\n",
      "/wiki/Pennsylvania_Governor%27s_School_for_the_Arts\n",
      "/wiki/Glory_Van_Scott\n",
      "/wiki/Circle_in_the_Square\n",
      "/wiki/Search_for_Tomorrow\n",
      "/wiki/Second_Stage_Theatre\n",
      "/wiki/Slab_Boys\n",
      "/wiki/Sean_Penn\n",
      "/wiki/Steve_Guttenberg\n",
      "/wiki/Daniel_Stern_(actor)\n",
      "/wiki/She%27s_Having_a_Baby\n",
      "/wiki/Joel_Schumacher\n",
      "/wiki/He_Said,_She_Said_(film)\n",
      "/wiki/Oliver_Stone\n",
      "/wiki/Meryl_Streep\n",
      "/wiki/Sleepers_(film)\n",
      "/wiki/Stir_of_Echoes\n",
      "/wiki/Sean_Penn\n",
      "/wiki/Michael_Strobl\n",
      "/wiki/Desert_Storm\n",
      "/wiki/Screen_Actors_Guild_Award_for_Outstanding_Performance_by_a_Male_Actor_in_a_Miniseries_or_Television_Movie\n",
      "/wiki/Sebastian_Shaw_(comics)\n",
      "/wiki/Saturn_Award_for_Best_Actor_on_Television\n",
      "/wiki/Kyra_Sedgwick\n",
      "/wiki/PBS\n",
      "/wiki/Lemon_Sky\n",
      "/wiki/Sosie_Bacon\n",
      "/wiki/Upper_West_Side\n",
      "/wiki/Six_Degrees_of_Kevin_Bacon\n",
      "/wiki/Six_degrees_of_separation\n",
      "/wiki/SixDegrees.org\n",
      "/wiki/Santa_Barbara_International_Film_Festival\n",
      "/wiki/Seattle_International_Film_Festival\n",
      "/wiki/Boston_Society_of_Film_Critics\n",
      "/wiki/Boston_Society_of_Film_Critics_Award_for_Best_Cast\n",
      "/wiki/Golden_Globe_Award_for_Best_Supporting_Actor_%E2%80%93_Motion_Picture\n",
      "/wiki/Golden_Globe_Award_for_Best_Actor_%E2%80%93_Television_Series_Musical_or_Comedy\n",
      "/wiki/Independent_Spirit_Awards\n",
      "/wiki/Independent_Spirit_Award_for_Best_Male_Lead\n",
      "/wiki/Primetime_Emmy_Award_for_Outstanding_Lead_Actor_in_a_Limited_Series_or_Movie\n",
      "/wiki/Satellite_Awards\n",
      "/wiki/Satellite_Award_for_Best_Actor_%E2%80%93_Motion_Picture\n",
      "/wiki/Satellite_Award_for_Best_Actor_%E2%80%93_Miniseries_or_Television_Film\n",
      "/wiki/Saturn_Award\n",
      "/wiki/Saturn_Award_for_Best_Actor_on_Television\n",
      "/wiki/Saturn_Award_for_Best_Actor_on_Television\n",
      "/wiki/Scream_Awards\n",
      "/wiki/Scream_Awards\n",
      "/wiki/Screen_Actors_Guild_Award\n",
      "/wiki/Screen_Actors_Guild_Award_for_Outstanding_Performance_by_a_Male_Actor_in_a_Supporting_Role\n",
      "/wiki/Screen_Actors_Guild_Award_for_Outstanding_Performance_by_a_Cast_in_a_Motion_Picture\n",
      "/wiki/Screen_Actors_Guild_Award_for_Outstanding_Performance_by_a_Cast_in_a_Motion_Picture\n",
      "/wiki/Screen_Actors_Guild_Award_for_Outstanding_Performance_by_a_Cast_in_a_Motion_Picture\n",
      "/wiki/Screen_Actors_Guild_Award_for_Outstanding_Performance_by_a_Male_Actor_in_a_Miniseries_or_Television_Movie\n",
      "/wiki/Beauty_Shop\n",
      "/wiki/Six_Degrees_of_Kevin_Bacon\n",
      "/wiki/SixDegrees.org\n",
      "/wiki/Sean_Penn\n",
      "/wiki/Philip_Seymour_Hoffman\n",
      "/wiki/Sean_Penn\n",
      "/wiki/Stacy_Keach\n",
      "/wiki/Gary_Sinise\n",
      "/wiki/Stanley_Tucci\n",
      "/wiki/Saturn_Award_for_Best_Actor_on_Television\n",
      "/wiki/Steven_Weber_(actor)\n",
      "/wiki/Stephen_Moyer\n",
      "/wiki/Sam_Heughan\n",
      "/wiki/Screen_Actors_Guild_Award_for_Outstanding_Performance_by_a_Male_Actor_in_a_Miniseries_or_Television_Movie\n",
      "/wiki/Gary_Sinise\n",
      "/wiki/Gary_Sinise\n",
      "/wiki/Alexander_Skarsg%C3%A5rd\n",
      "/wiki/International_Standard_Name_Identifier\n",
      "/wiki/RERO_(Library_Network_of_Western_Switzerland)\n",
      "/wiki/SNAC\n",
      "/wiki/Syst%C3%A8me_universitaire_de_documentation\n"
     ]
    }
   ],
   "source": [
    "# Retrieve an arbitrary Wikipedia page and produces a list of links on that page\n",
    "# Retrieve only the desired article links by using the regular expression\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# article links 和 其他 links 的区别\n",
    "# they reside within the div within the id set to bodyContent\n",
    "# The urls do not contain colons\n",
    "# The urls begin with /wiki/\n",
    "\n",
    "html = urlopen('http://en.wikipedia.org/wiki/Kevin_Bacon')\n",
    "bs = BeautifulSoup(html,'html.parser')\n",
    "for link in bs.find('div', {'id':'bodyContent'}).find_all(\n",
    "    'a', href=re.compile('^(/wiki/)((?!:).)*S')):\n",
    "    if 'href' in link.attrs:\n",
    "        print(link.attrs['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
